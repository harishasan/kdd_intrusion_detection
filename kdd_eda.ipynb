{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Dataset is taken from here: https://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html.\n",
    "\n",
    "Task is to build a network intrusion detector, a predictive model capable of distinguishing between 'bad' connections, called intrusions or attacks, and 'good' normal connections. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: setting it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#disable auto save, this sometimes hangs the browser\n",
    "%autosave 0\n",
    "# need this to properly plot graphs using matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "# to supress printing of exponential notation in pandas\n",
    "pd.options.display.float_format = '{:20,.2f}'.format\n",
    "\n",
    "# avoid data truncation\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# plotly settings\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "print __version__ # requires version >= 1.9.0\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import numpy\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "#### Print box plot grouped by  unique label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_box_plot_grouped_by_label(data, feature_column, label_column):\n",
    "    x = data[label_column].unique()\n",
    "\n",
    "    traces = []\n",
    "    for label in x:\n",
    "        trace = go.Box(y = numpy.array(data.loc[data[label_column] == label][feature_column]), name = label)\n",
    "        traces.append(trace)\n",
    "\n",
    "    iplot(traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print histograms of correlated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_correlated_column_histogram(data, column_names):\n",
    "    sorted_data = {}\n",
    "    for column in column_names:\n",
    "        sorted_data[column] = pd.Series.sort_values(data[column])\n",
    "\n",
    "    traces = []\n",
    "    for column in column_names:\n",
    "        traces.append(go.Histogram(x = sorted_data[column], name = column, opacity=0.5))\n",
    "\n",
    "    histogramData = traces\n",
    "    layout = go.Layout(barmode='overlay')\n",
    "    fig = go.Figure(data = histogramData, layout=layout)\n",
    "    iplot(fig, filename='overlaid histogram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print normal vs abnormal box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_normal_abnormal_box_plot(data, column):\n",
    "    normal = data.loc[data.label == 'normal.']\n",
    "    abnormal = data.loc[data.label != 'normal.']    \n",
    "    trace0 = go.Box(y= normal[column], name = 'Normal')\n",
    "    trace1 = go.Box(y= abnormal[column], name = 'Abnormal')\n",
    "    boxData = [trace0, trace1]\n",
    "    iplot(boxData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print normal vs abnormal scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_normal_vs_abnormal_scatter_plot(data_source, col1, col2): \n",
    "\n",
    "    normal = data_source.loc[data_source.label == 'normal.']\n",
    "    abnormal = data_source.loc[data_source.label != 'normal.']\n",
    "\n",
    "    # keep only the required columns and remove duplicate points\n",
    "    # otherwise graphs become too heavy and chrome gets stuck\n",
    "    normal = normal.loc[:,[col1, col2,]]\n",
    "    normal = normal.drop_duplicates()\n",
    "    abnormal = abnormal.loc[:,[col1, col2,]]\n",
    "    abnormal = abnormal.drop_duplicates()\n",
    "\n",
    "    # Create a trace\n",
    "    trace0 = go.Scatter(\n",
    "        x = normal[col1],\n",
    "        y = normal[col2],\n",
    "        mode = 'markers',\n",
    "        name = 'normal',\n",
    "        marker = dict(opacity= 0.8)\n",
    "    )\n",
    "\n",
    "    # name the x and y axis\n",
    "    trace1 = go.Scatter(\n",
    "        x = abnormal[col1],\n",
    "        y = abnormal[col2],\n",
    "        mode = 'markers',\n",
    "        name = 'abnormal',\n",
    "        marker = dict(opacity= 0.8)\n",
    "    )\n",
    "\n",
    "    tempData = [trace0, trace1]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        xaxis=dict(title=col1),\n",
    "        yaxis=dict(title=col2)\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data = tempData, layout=layout)\n",
    "\n",
    "    # Plot and embed in ipython notebook!\n",
    "    iplot(fig, filename='basic-scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print correlation scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_correlation_scatter_plots(data, columns):\n",
    "    max_value = -1\n",
    "    for col in columns:\n",
    "        temp = numpy.max(data[col].unique())\n",
    "        if temp > max_value:\n",
    "            max_value = temp\n",
    "\n",
    "    row_count = len(data)\n",
    "    x_axis = numpy.linspace(0, max_value, row_count)\n",
    "\n",
    "    for col in columns:\n",
    "        trace = go.Scatter(\n",
    "            x = x_axis,\n",
    "            y = data[col],\n",
    "            mode = 'line',\n",
    "            name = col)\n",
    "\n",
    "        print iplot([trace], filename='line-mode')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Returns true if array contains 1 zero and 1 one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_only_zero_and_one(array):\n",
    "    return len(array) == 2 and ((array[0] == 0 and array[1] == 1) or ((array[0] == 1 and array[1] == 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/haris/Desktop/kdd/kdd_full.csv\")\n",
    "print \"csv loaded\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: analyzing metadata\n",
    "\n",
    "### Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'rows and columns: ' + str(data.shape)\n",
    "# remove duplicate rows\n",
    "data = data.drop_duplicates()\n",
    "print 'rows and columns after removing duplicates:' + str(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique class label count in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print number of unique class labels\n",
    "len(data['label'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage-wise distribution of class labels in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rows_count = data.shape[0]\n",
    "data.groupby('label').size() * 100/rows_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generally in anomaly detection problem,  and particularly in this dataset, most of the data is normal (75%) and small subset is anomalous. And for this dataset within anomalous we have 22 different class labels. Therefore it makes more sense to first train a model to identify an input row as normal/anomalous (1/0). Then, if it is anomalous, use a different model to identify type of anomaly. This approach has an added advantage of being more effective against unseen anomalies. \n",
    "#### If needed, we can take this approach even further and within anomalous first do neptune(22%) detection and then rest accordingly.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do we need to fill missing values? Count rows with null values in it for any column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(data[data.isnull().any(axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Individual feature analysis\n",
    "### Questions we are trying to answer: \n",
    "1. Is there any feature that can be removed because it has no impact on class label? \n",
    "2. Is there any feature that clearly differentiate between different class labels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features that can be removed because they have no impact on class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Features that can be removed because they have a single value throughout the column\n",
    "for col in numpy.array(data.columns):\n",
    "    if len(data[col].unique()) == 1:\n",
    "        print col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print features with low std dev, excluding categorical and binary value (1/0) features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical = ['protocol_type', 'service', 'flag', 'label']\n",
    "for col in numpy.array(data.columns):\n",
    "    if col not in categorical:\n",
    "        unique_values = numpy.array(data[col].unique())\n",
    "        if not is_only_zero_and_one(unique_values):\n",
    "            std_dev = numpy.std(data[col])\n",
    "            if std_dev < 0.1:                          \n",
    "                print col + ': ' + str(std_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing columns with low std dev (< 0.1)\n",
    "#### Goal is to see if we can remove some low std dev features if they are not helping in determing any class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_box_plot_grouped_by_label(data, 'urgent', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_box_plot_grouped_by_label(data, 'num_failed_logins', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_box_plot_grouped_by_label(data, 'wrong_fragment', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_box_plot_grouped_by_label(data, 'su_attempted', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_box_plot_grouped_by_label(data, 'dst_host_srv_diff_host_rate', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_box_plot_grouped_by_label(data, 'num_shells', 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: Features with low std dev be very effective in classifying the type of anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features: we listed distribution of categorical features against class labels to see if we can find any pattern, but we didn't. Categorical features are uniformly distributed across various class labels.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# see how categorical attribute protocol_type is contributing to various labels\n",
    "data.groupby(['protocol_type', 'label']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# see how categorical attribute service is contributing to various labels\n",
    "data.groupby(['service', 'label']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# see how categorical attribute flag is contributing to various labels\n",
    "data.groupby(['flag', 'label']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minor findings on categorical feature\n",
    "1. wherever service value is \"http_2784\" or \"harvest\" class label is \"satan\"\n",
    "2. whenever the flag is \"RSTOS0\", class label is always \"portsweep\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: so far we have seen that there is one feature that has no impact on class label and can be removed. Furthermore, there exist no limited subset of features that can be used to predict the label alone, we will have to train the model using all features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: finding correlated features\n",
    "#### Question we are trying to answer: are there any highly correlated features in the dataset? If yes, we can reduce the feature set by removing redundant columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairsSet = set()\n",
    "# skipping some columns\n",
    "# first three are categorical\n",
    "columns_to_skip = ['flag', 'protocol_type', 'service', 'num_outbound_cmds', 'label']\n",
    "\n",
    "for column in data.columns:\n",
    "    # print column\n",
    "    for inner_column in data.columns:\n",
    "        if column not in columns_to_skip and inner_column not in columns_to_skip:\n",
    "            \n",
    "            key1 = column + '-' + inner_column\n",
    "            key2 = inner_column + '-' + column\n",
    "            \n",
    "            if column != inner_column and key1 not in pairsSet and key2 not in pairsSet:\n",
    "                # print column + \" -- \" + inner_column                \n",
    "                pairsSet.add(key1)\n",
    "                pairsSet.add(key2)\n",
    "                correlation = numpy.corrcoef(data[column], data[inner_column])[0, 1]\n",
    "                # list all column pairs where correlation is >= 0.75\n",
    "                if correlation >= 0.75:\n",
    "                    print column + \" -- \" + inner_column\n",
    "                    print correlation\n",
    "                \n",
    "print 'DONE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot correlated columms\n",
    "### Correlation : serror_rate | dst_host_srv_serror_rate | srv_serror_rate | dst_host_serror_rate => 0.99 correlation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These four features have exactly same mean, std dev, interquartile ranger but are they really same and highly correlated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print data['serror_rate'].describe()\n",
    "print data['dst_host_srv_serror_rate'].describe()\n",
    "print data['srv_serror_rate'].describe()\n",
    "print data['dst_host_serror_rate'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing line plot to visualize the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_correlation_scatter_plots(data, ['dst_host_serror_rate', \n",
    "                                       'dst_host_srv_serror_rate',\n",
    "                                       'serror_rate', \n",
    "                                       'srv_serror_rate'\n",
    "                                       ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print scatter matrix to visualize the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = data[['dst_host_serror_rate', 'dst_host_srv_serror_rate', 'serror_rate', 'srv_serror_rate']]\n",
    "print scatter_matrix(df, alpha=0.2, figsize=(10, 10), diagonal='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By looking at various plots above we can conclude that although these features are at some places correlated but overall correlation is not so high that we can drop the feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation : num_compromised | num_root => 0.99 correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print data['num_root'].describe()\n",
    "print data['num_compromised'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# columns have slightly different max value so applying scaling\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "num_compromised_scaled = min_max_scaler.fit_transform(data['num_compromised'])\n",
    "num_root_scaled = min_max_scaler.fit_transform(data['num_root'])\n",
    "\n",
    "row_count = len(data)\n",
    "x_axis = numpy.linspace(0, 1, row_count)\n",
    "\n",
    "trace0 = go.Scatter(x = x_axis, y = num_compromised_scaled, mode = 'line', name = 'num_compromised')\n",
    "trace1 = go.Scatter(x = x_axis, y = num_root_scaled, mode = 'line', name = 'num_root')\n",
    "\n",
    "df = data[['num_root', 'num_compromised']]\n",
    "print scatter_matrix(df, alpha=0.2, figsize=(10, 10), diagonal='kde')\n",
    "\n",
    "print iplot([trace0], filename='line-mode')\n",
    "print iplot([trace1], filename='line-mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print print_box_plot_grouped_by_label(data, 'num_root', 'label')\n",
    "print print_box_plot_grouped_by_label(data, 'num_compromised', 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here correlation is very high and looks like we can drop one of these features from feature set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation: rerror_rate | dst_host_rerror_rate | dst_host_srv_rerror_rate | srv_rerror_rate\n",
    "1. rerror_rate : srv_rerror_rate => 0.98959088658\n",
    "2. rerror_rate : dst_host_rerror_rate => 0.965840027856\n",
    "3. dst_host_rerror_rate : dst_host_srv_rerror_rate => 0.961246461143\n",
    "4. srv_rerror_rate : dst_host_srv_rerror_rate => 0.959543136155\n",
    "5. rerror_rate : dst_host_srv_rerror_rate => 0.958523973064\n",
    "6. rv_rerror_rate : dst_host_rerror_rate => 0.956401661999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print data['rerror_rate'].describe()\n",
    "print data['dst_host_rerror_rate'].describe()\n",
    "print data['dst_host_srv_rerror_rate'].describe()\n",
    "print data['srv_rerror_rate'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_correlation_scatter_plots(data,\n",
    "    ['rerror_rate',\n",
    "    'srv_rerror_rate',\n",
    "    'dst_host_srv_rerror_rate',\n",
    "    'dst_host_rerror_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = data[['rerror_rate', 'srv_rerror_rate', 'dst_host_srv_rerror_rate', 'dst_host_rerror_rate']]\n",
    "print scatter_matrix(df, alpha=0.2, figsize=(10, 10), diagonal='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Again, there is some correlation but not high enough to drop the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: we have found one highly correlated features in the dataset. Based on this we can reduce one feature from our feature-set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Compare anomalous and normal data: Single Feature\n",
    "#### Questions we are trying to answer: does anomalous and normal data has some kind of distiction that can help us in prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_normal_abnormal_box_plot(data, 'srv_serror_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_normal_abnormal_box_plot(data, 'dst_host_srv_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion: there exist features that have different pattern for normal and anomalous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Compare anomalous and normal data: Multiple features\n",
    "#### Questions we are trying to answer: can creation of new features (if needed) help us in prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_normal_vs_abnormal_scatter_plot(data, 'count', 'same_srv_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_normal_vs_abnormal_scatter_plot(data, 'srv_count', 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_normal_vs_abnormal_scatter_plot(data, 'num_root', 'wrong_fragment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tempData = data.loc[data['dst_bytes'] < 1000000]\n",
    "print_normal_vs_abnormal_scatter_plot(tempData, 'dst_bytes', 'num_file_creations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_normal_vs_abnormal_scatter_plot(data, 'duration', 'dst_host_same_src_port_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Conclusion:\n",
    "1. We found one column that has no impact on class label.\n",
    "2. We found few correlated columns which can help in reducing feature set.\n",
    "3. We found that it might be more suitable to first detect normal vs anomalous (1/0) and then predict the type of anomaly. \n",
    "4. We found that there exist no single or subset of features which alone can do the prediction. However, many features provide some level of distinction between class labels. Therefore by using all the available features together we can make a good prediction.\n",
    "5. If needed, we can make new features by combining existing features. Or we can give neural networks a try which can automatically do this for us. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Next Steps:\n",
    "To find out how accurate our data analysis has been we can do following\n",
    "To find out how accurate our data analysis has been we can do following\n",
    "1. Convert categorical features into continous or binary (1/0) features\n",
    "2. Rescale all the features between 0 and 1\n",
    "3. Using stratified samping create three sets (1) test (2) train (3) cross validation\n",
    "4. Implement a dummpy classifier and note results //http://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html\n",
    "5. Select a machine learning algorithm to apply on dataset\n",
    "6. Apply selected machine learning algorithm using all features and get the baseline accuracy of algoithm. Note the train and cross validation errors. \n",
    "7. Apply the selected machine learning algorithm using subset of features identified in EDA. Note the train and cross validation errors. \n",
    "8. Use the two step approach i.e. normal vs anomalous and then predict type of anomaly. Use all features present in feature set. Note the train and cross validation errors.\n",
    "9. Repeat previous step using the subset of features identified in EDA. Note the train and cross validation errors. \n",
    "10. Repeat steps 6-9 using a Neural network\n",
    "11. Apply the best method on test set to get final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
