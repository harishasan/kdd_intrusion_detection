{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Prepare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "#disable auto save, this sometimes hangs the browser\n",
    "%autosave 0\n",
    "import pandas as pd\n",
    "import time\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import numpy\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import cross_validation\n",
    "from sklearn import preprocessing\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import operator \n",
    "\n",
    "# to supress printing of exponential notation in pandas\n",
    "pd.options.display.float_format = '{:20,.2f}'.format\n",
    "\n",
    "# avoid data truncation\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to return true if array contains binary (zero and one) values only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_only_zero_and_one(array):\n",
    "    return len(array) == 2 and ((array[0] == 0 and array[1] == 1) or ((array[0] == 1 and array[1] == 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to convert categorical features into binary\n",
    "#### use this in future instead: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html\n",
    "#### need to do this because: https://stackoverflow.com/questions/24715230/can-sklearn-random-forest-directly-handle-categorical-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# does not modify the original source\n",
    "def convert_categorical_to_binary(data, categorical_columns):\n",
    "    \n",
    "    temp_data = data.copy()\n",
    "\n",
    "    label_binarizer = []\n",
    "    for col in categorical_columns:\n",
    "        label_binarizer.append((col, sklearn.preprocessing.LabelBinarizer()))\n",
    "        \n",
    "    # df_out=True: output a data frame\n",
    "    mapper_df = DataFrameMapper(label_binarizer, df_out=True)    \n",
    "    # temp contains the new columns\n",
    "    temp = mapper_df.fit_transform(temp_data)\n",
    "    \n",
    "    # print temp[temp.isnull().any(axis=1)]\n",
    "    \n",
    "    for col in temp.columns:\n",
    "        temp_data[col] = numpy.array(temp[col])\n",
    "    \n",
    "    total_column_count = len(data.columns)\n",
    "    for col in categorical_columns:\n",
    "        total_column_count += len(data[col].unique())\n",
    "        \n",
    "    print 'new column count should be ' + str(len(temp_data.columns)) + ' and is ' + str(total_column_count)\n",
    "    return temp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to rescale all non-binary features between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# does not modify the original source\n",
    "# categorical_columns are skipped\n",
    "# if a column only has binary (0/1) values, it is skipped too\n",
    "def rescale_non_binary_columns(data, categorical_columns):\n",
    "    \n",
    "    temp_data = data.copy()\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    for col in data.columns:\n",
    "        if col not in categorical_columns and not is_only_zero_and_one(data[col].unique()):\n",
    "            # print 'scaling ' + col\n",
    "            temp_data[col] = scaler.fit_transform(temp_data[[col]])\n",
    "            \n",
    "    return temp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to print confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_confusion_matrix(confusion_matrix, labels):\n",
    "    records = len(labels)\n",
    "    for row in range(records):\n",
    "        print \"-------------\" + labels[row] + \"-------------\"\n",
    "        total = 0\n",
    "        for column in range(records):\n",
    "            total += confusion_matrix[row][column]\n",
    "        print 'total: ' + str(total)\n",
    "        print 'correct: ' + str(confusion_matrix[row][row])\n",
    "        for column in range(records):\n",
    "            if confusion_matrix[row][column] != 0 and row != column:\n",
    "                print labels[column] + ': ' + str(confusion_matrix[row][column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to print summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_summary_statistics(confusion_matrix, normal_class_index):\n",
    "    class_label_count = len(confusion_matrix)\n",
    "    total_records = 0\n",
    "    total_normal = 0\n",
    "    total_anomalous = 0\n",
    "    total_normal_correctly_identified = 0\n",
    "    total_anomalous_correctly_identified = 0\n",
    "    \n",
    "    for row in range(class_label_count):\n",
    "        for col in range(class_label_count):            \n",
    "            total_records += confusion_matrix[row][col]            \n",
    "            if row == normal_class_index:\n",
    "                total_normal += confusion_matrix[row][col]\n",
    "                if col == normal_class_index:\n",
    "                    total_normal_correctly_identified = confusion_matrix[row][col]\n",
    "            else:\n",
    "                total_anomalous += confusion_matrix[row][col]\n",
    "                if row == col:\n",
    "                    total_anomalous_correctly_identified += confusion_matrix[row][col]\n",
    "     \n",
    "    # * by 1.0 to make denominator float\n",
    "    #  If the numerator or denominator is a float, then the result will be also.\n",
    "    total_correctly_identified = total_normal_correctly_identified + total_anomalous_correctly_identified\n",
    "    correct_normal_percentage = total_normal_correctly_identified * 100/(1.0 * total_normal)\n",
    "    correct_anomalous_percentage = total_anomalous_correctly_identified * 100/(1.0 * total_anomalous)\n",
    "    correct_total_percentage = total_correctly_identified * 100/(1.0 * total_records)\n",
    "    print 'total: ' + str(total_records)\n",
    "    print 'normal: ' + str(total_normal)\n",
    "    print 'anomalous: ' + str(total_anomalous)\n",
    "    \n",
    "    print 'total correctly identified: ' + str(total_correctly_identified) + '(' + str(correct_total_percentage) + '%)'\n",
    "    print 'normal correctly identified: ' + str(total_normal_correctly_identified) + '(' + str(correct_normal_percentage) + '%)'\n",
    "    print 'anomalous correctly identified: ' + str(total_anomalous_correctly_identified) + '(' + str(correct_anomalous_percentage) + '%)'\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to print F scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_f_scores(actual_labels, predictions, unique_labels):\n",
    "    #http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n",
    "    # Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "    print 'micro: ' + str(metrics.f1_score(actual_labels, predictions, \n",
    "                                           labels=unique_labels, average='micro'))\n",
    "    # Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
    "    print 'macro: '+ str(metrics.f1_score(actual_labels, predictions, \n",
    "                                          labels=unique_labels, average='macro'))\n",
    "    # Calculate metrics for each label, and find their average, weighted by support (the number of true instances \n",
    "    # for each label). This alters ‘macro’ to account for label imbalance; it can result in an F-score that\n",
    "    # is not between precision and recall.\n",
    "    print 'weighted: ' + str(metrics.f1_score(actual_labels, predictions, \n",
    "                                              labels=unique_labels, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load train and cross validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csvs loaded\n",
      "644994 train rows\n",
      "214999 cross validation rows\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"/Users/haris/Desktop/kdd_datasets/train.csv\")\n",
    "cross_validation = pd.read_csv(\"/Users/haris/Desktop/kdd_datasets/cross_validation.csv\")\n",
    "print \"csvs loaded\"\n",
    "print str(len(train)) + ' train rows'\n",
    "print str(len(cross_validation)) + ' cross validation rows'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting string class labels to int for Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22]\n",
      "[ 0  2  3  5  8  6  4  7  1  9 18 14 12 15 13 10 11 19 17 16 21 20]\n"
     ]
    }
   ],
   "source": [
    "labels = train.append(cross_validation)['label'].unique()\n",
    "print len(labels)\n",
    "label_to_index_map = {}\n",
    "index_to_label_map = {}\n",
    "index = 0\n",
    "\n",
    "for label in labels:\n",
    "    index_to_label_map[index] = label\n",
    "    label_to_index_map[label] = index\n",
    "    index += 1\n",
    "    \n",
    "train['label'] = train['label'].map(lambda item: label_to_index_map[item])\n",
    "cross_validation['label'] = cross_validation['label'].map(lambda item: label_to_index_map[item])\n",
    "print train['label'].unique()\n",
    "print cross_validation['label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train and cross validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = train['label']\n",
    "X_train = train.drop('label', 1) \n",
    "y_cross_validation = cross_validation['label']\n",
    "X_cross_validation = cross_validation.drop('label', 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train several Neural Networks using different activation/alpha/hidden_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns: 122\n",
      "labels: 23\n",
      "------------------------------\n",
      "hidden_layer: ()\n",
      "activation: relu\n",
      "alphas: 0.0001\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 214495(99.765580305%)\n",
      "normal correctly identified: 162505(99.9643215246%)\n",
      "anomalous correctly identified: 51990(99.1494393165%)\n",
      "micro: 0.99765580305\n",
      "macro: 0.495800111127\n",
      "weighted: 0.997151003655\n",
      "total prediction time: 46.4818029404 seconds\n",
      "------------------------------\n",
      "hidden_layer: ()\n",
      "activation: relu\n",
      "alphas: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haris/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/haris/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 214405(99.7237196452%)\n",
      "normal correctly identified: 162515(99.9704729859%)\n",
      "anomalous correctly identified: 51890(98.9587306431%)\n",
      "micro: 0.997237196452\n",
      "macro: 0.457858951859\n",
      "weighted: 0.996530909473\n",
      "total prediction time: 42.3355970383 seconds\n",
      "------------------------------\n",
      "hidden_layer: ()\n",
      "activation: relu\n",
      "alphas: 0.001\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 214367(99.7060451444%)\n",
      "normal correctly identified: 162499(99.9606306478%)\n",
      "anomalous correctly identified: 51868(98.9167747349%)\n",
      "micro: 0.997060451444\n",
      "macro: 0.455286033162\n",
      "weighted: 0.996346931121\n",
      "total prediction time: 37.9416491985 seconds\n",
      "------------------------------\n",
      "hidden_layer: ()\n",
      "activation: relu\n",
      "alphas: 0.02\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 213950(99.5120907539%)\n",
      "normal correctly identified: 162506(99.9649366707%)\n",
      "anomalous correctly identified: 51444(98.1081699596%)\n",
      "micro: 0.995120907539\n",
      "macro: 0.304475825502\n",
      "weighted: 0.993775658956\n",
      "total prediction time: 25.0951809883 seconds\n",
      "------------------------------\n",
      "hidden_layer: ()\n",
      "activation: relu\n",
      "alphas: 0.2\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 213063(99.0995306955%)\n",
      "normal correctly identified: 162547(99.990157662%)\n",
      "anomalous correctly identified: 50516(96.3383934701%)\n",
      "micro: 0.990995306955\n",
      "macro: 0.224856454874\n",
      "weighted: 0.988387873005\n",
      "total prediction time: 25.1686019897 seconds\n",
      "------------------------------\n",
      "hidden_layer: ()\n",
      "activation: logistic\n",
      "alphas: 0.0001\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 214495(99.765580305%)\n",
      "normal correctly identified: 162505(99.9643215246%)\n",
      "anomalous correctly identified: 51990(99.1494393165%)\n",
      "micro: 0.99765580305\n",
      "macro: 0.495792151094\n",
      "weighted: 0.997151001686\n",
      "total prediction time: 46.4087991714 seconds\n",
      "------------------------------\n",
      "hidden_layer: ()\n",
      "activation: logistic\n",
      "alphas: 0.0005\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 214402(99.7223242899%)\n",
      "normal correctly identified: 162513(99.9692426936%)\n",
      "anomalous correctly identified: 51889(98.9568235563%)\n",
      "micro: 0.997223242899\n",
      "macro: 0.457424994507\n",
      "weighted: 0.996513788287\n",
      "total prediction time: 42.1574859619 seconds\n",
      "------------------------------\n",
      "hidden_layer: ()\n",
      "activation: logistic\n",
      "alphas: 0.001\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 214369(99.7069753813%)\n",
      "normal correctly identified: 162499(99.9606306478%)\n",
      "anomalous correctly identified: 51870(98.9205889084%)\n",
      "micro: 0.997069753813\n",
      "macro: 0.455345980977\n",
      "weighted: 0.996356407785\n",
      "total prediction time: 37.8237040043 seconds\n",
      "------------------------------\n",
      "hidden_layer: ()\n",
      "activation: logistic\n",
      "alphas: 0.02\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 213950(99.5120907539%)\n",
      "normal correctly identified: 162506(99.9649366707%)\n",
      "anomalous correctly identified: 51444(98.1081699596%)\n",
      "micro: 0.995120907539\n",
      "macro: 0.304475825502\n",
      "weighted: 0.993775658956\n",
      "total prediction time: 25.2665550709 seconds\n",
      "------------------------------\n",
      "hidden_layer: ()\n",
      "activation: logistic\n",
      "alphas: 0.2\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 213063(99.0995306955%)\n",
      "normal correctly identified: 162547(99.990157662%)\n",
      "anomalous correctly identified: 50516(96.3383934701%)\n",
      "micro: 0.990995306955\n",
      "macro: 0.224856454874\n",
      "weighted: 0.988387873005\n",
      "total prediction time: 23.8102509975 seconds\n",
      "------------------------------\n",
      "hidden_layer: 5\n",
      "activation: relu\n",
      "alphas: 0.0001\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 214732(99.8758133759%)\n",
      "normal correctly identified: 162463(99.9384853872%)\n",
      "anomalous correctly identified: 52269(99.6815165154%)\n",
      "micro: 0.998758133759\n",
      "macro: 0.525331753765\n",
      "weighted: 0.998711918642\n",
      "total prediction time: 77.3038561344 seconds\n",
      "------------------------------\n",
      "hidden_layer: 5\n",
      "activation: relu\n",
      "alphas: 0.0005\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 214649(99.8372085452%)\n",
      "normal correctly identified: 162467(99.9409459717%)\n",
      "anomalous correctly identified: 52182(99.5155999695%)\n",
      "micro: 0.998372085452\n",
      "macro: 0.456118841343\n",
      "weighted: 0.998247728618\n",
      "total prediction time: 94.8329741955 seconds\n",
      "------------------------------\n",
      "hidden_layer: 5\n",
      "activation: relu\n",
      "alphas: 0.001\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 214635(99.830696887%)\n",
      "normal correctly identified: 162470(99.9427914101%)\n",
      "anomalous correctly identified: 52165(99.483179495%)\n",
      "micro: 0.99830696887\n",
      "macro: 0.454020229737\n",
      "weighted: 0.998187234212\n",
      "total prediction time: 100.987263203 seconds\n",
      "------------------------------\n",
      "hidden_layer: 5\n",
      "activation: relu\n",
      "alphas: 0.02\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 214057(99.5618584272%)\n",
      "normal correctly identified: 162496(99.9587852094%)\n",
      "anomalous correctly identified: 51561(98.3312991075%)\n",
      "micro: 0.995618584272\n",
      "macro: 0.308376079965\n",
      "weighted: 0.994377821091\n",
      "total prediction time: 55.2607808113 seconds\n",
      "------------------------------\n",
      "hidden_layer: 5\n",
      "activation: relu\n",
      "alphas: 0.2\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 213439(99.2744152298%)\n",
      "normal correctly identified: 162451(99.9311036337%)\n",
      "anomalous correctly identified: 50988(97.2385384087%)\n",
      "micro: 0.992744152298\n",
      "macro: 0.230850169314\n",
      "weighted: 0.990609117787\n",
      "total prediction time: 36.1752669811 seconds\n",
      "------------------------------\n",
      "hidden_layer: 5\n",
      "activation: logistic\n",
      "alphas: 0.0001\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 214555(99.7934874116%)\n",
      "normal correctly identified: 162482(99.9501731636%)\n",
      "anomalous correctly identified: 52073(99.3077275154%)\n",
      "micro: 0.997934874116\n",
      "macro: 0.424674659683\n",
      "weighted: 0.997494230553\n",
      "total prediction time: 70.4030089378 seconds\n",
      "------------------------------\n",
      "hidden_layer: 5\n",
      "activation: logistic\n",
      "alphas: 0.0005\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 214471(99.7544174624%)\n",
      "normal correctly identified: 162486(99.9526337481%)\n",
      "anomalous correctly identified: 51985(99.1399038828%)\n",
      "micro: 0.997544174624\n",
      "macro: 0.370763561883\n",
      "weighted: 0.99693158402\n",
      "total prediction time: 63.3962228298 seconds\n",
      "------------------------------\n",
      "hidden_layer: 5\n",
      "activation: logistic\n",
      "alphas: 0.001\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 214422(99.7316266587%)\n",
      "normal correctly identified: 162496(99.9587852094%)\n",
      "anomalous correctly identified: 51926(99.0273857655%)\n",
      "micro: 0.997316266587\n",
      "macro: 0.355320349565\n",
      "weighted: 0.996516249504\n",
      "total prediction time: 59.0325591564 seconds\n",
      "------------------------------\n",
      "hidden_layer: 5\n",
      "activation: logistic\n",
      "alphas: 0.02\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 213859(99.4697649757%)\n",
      "normal correctly identified: 162525(99.9766244471%)\n",
      "anomalous correctly identified: 51334(97.8983904188%)\n",
      "micro: 0.994697649757\n",
      "macro: 0.282774471932\n",
      "weighted: 0.992993444672\n",
      "total prediction time: 30.4823551178 seconds\n",
      "------------------------------\n",
      "hidden_layer: 5\n",
      "activation: logistic\n",
      "alphas: 0.2\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 210973(98.1274331509%)\n",
      "normal correctly identified: 162553(99.9938485387%)\n",
      "anomalous correctly identified: 48420(92.341139675%)\n",
      "micro: 0.981274331509\n",
      "macro: 0.0860216336147\n",
      "weighted: 0.972082315961\n",
      "total prediction time: 24.2877600193 seconds\n",
      "------------------------------\n",
      "hidden_layer: 104\n",
      "activation: relu\n",
      "alphas: 0.0001\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 214851(99.9311624705%)\n",
      "normal correctly identified: 162528(99.9784698855%)\n",
      "anomalous correctly identified: 52323(99.784499199%)\n",
      "micro: 0.999311624705\n",
      "macro: 0.557628206398\n",
      "weighted: 0.999264138536\n",
      "total prediction time: 74.4535751343 seconds\n",
      "------------------------------\n",
      "hidden_layer: 104\n",
      "activation: relu\n",
      "alphas: 0.0005\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 214836(99.9241856939%)\n",
      "normal correctly identified: 162527(99.9778547394%)\n",
      "anomalous correctly identified: 52309(99.7577999847%)\n",
      "micro: 0.999241856939\n",
      "macro: 0.562467761667\n",
      "weighted: 0.99919375977\n",
      "total prediction time: 80.9722690582 seconds\n",
      "------------------------------\n",
      "hidden_layer: 104\n",
      "activation: relu\n",
      "alphas: 0.001\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 214820(99.9167437988%)\n",
      "normal correctly identified: 162532(99.98093047%)\n",
      "anomalous correctly identified: 52288(99.7177511633%)\n",
      "micro: 0.999167437988\n",
      "macro: 0.550017519506\n",
      "weighted: 0.999111550608\n",
      "total prediction time: 73.9423501492 seconds\n",
      "------------------------------\n",
      "hidden_layer: 104\n",
      "activation: relu\n",
      "alphas: 0.02\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 214495(99.765580305%)\n",
      "normal correctly identified: 162488(99.9538640404%)\n",
      "anomalous correctly identified: 52007(99.181859791%)\n",
      "micro: 0.99765580305\n",
      "macro: 0.405426956412\n",
      "weighted: 0.997176987457\n",
      "total prediction time: 55.3733029366 seconds\n",
      "------------------------------\n",
      "hidden_layer: 104\n",
      "activation: relu\n",
      "alphas: 0.2\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 213669(99.3813924716%)\n",
      "normal correctly identified: 162470(99.9427914101%)\n",
      "anomalous correctly identified: 51199(97.6409337097%)\n",
      "micro: 0.993813924716\n",
      "macro: 0.251702102879\n",
      "weighted: 0.991900377612\n",
      "total prediction time: 54.4076521397 seconds\n",
      "------------------------------\n",
      "hidden_layer: 104\n",
      "activation: logistic\n",
      "alphas: 0.0001\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 214781(99.8986041796%)\n",
      "normal correctly identified: 162479(99.9483277253%)\n",
      "anomalous correctly identified: 52302(99.7444503776%)\n",
      "micro: 0.998986041796\n",
      "macro: 0.573328316521\n",
      "weighted: 0.998947897166\n",
      "total prediction time: 117.284729004 seconds\n",
      "------------------------------\n",
      "hidden_layer: 104\n",
      "activation: logistic\n",
      "alphas: 0.0005\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 214625(99.8260457025%)\n",
      "normal correctly identified: 162475(99.9458671407%)\n",
      "anomalous correctly identified: 52150(99.454573194%)\n",
      "micro: 0.998260457025\n",
      "macro: 0.514923443034\n",
      "weighted: 0.998000838267\n",
      "total prediction time: 87.081897974 seconds\n",
      "------------------------------\n",
      "hidden_layer: 104\n",
      "activation: logistic\n",
      "alphas: 0.001\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 214620(99.8237201103%)\n",
      "normal correctly identified: 162486(99.9526337481%)\n",
      "anomalous correctly identified: 52134(99.4240598062%)\n",
      "micro: 0.998237201103\n",
      "macro: 0.490219387102\n",
      "weighted: 0.997873377224\n",
      "total prediction time: 78.1381671429 seconds\n",
      "------------------------------\n",
      "hidden_layer: 104\n",
      "activation: logistic\n",
      "alphas: 0.02\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 213972(99.5223233596%)\n",
      "normal correctly identified: 162491(99.9557094788%)\n",
      "anomalous correctly identified: 51481(98.1787321687%)\n",
      "micro: 0.995223233596\n",
      "macro: 0.303075543907\n",
      "weighted: 0.993876658763\n",
      "total prediction time: 44.6258821487 seconds\n",
      "------------------------------\n",
      "hidden_layer: 104\n",
      "activation: logistic\n",
      "alphas: 0.2\n",
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 212342(98.7641802985%)\n",
      "normal correctly identified: 162540(99.9858516391%)\n",
      "anomalous correctly identified: 49802(94.9767335418%)\n",
      "micro: 0.987641802985\n",
      "macro: 0.187249744927\n",
      "weighted: 0.983623682519\n",
      "total prediction time: 56.6161241531 seconds\n"
     ]
    }
   ],
   "source": [
    "#(10,10,10) if you want 3 hidden layers with 10 hidden units each\n",
    "# activation: relu, logistic\n",
    "# alpha(regularization)\n",
    "# random_state\n",
    "columns_count = len(X_train.columns)\n",
    "print 'columns: ' + str(columns_count)\n",
    "labels_count = len(labels)\n",
    "print 'labels: ' + str(labels_count)\n",
    "neurons_1 = columns_count/labels_count\n",
    "neurons_2 = columns_count * 2/3 + labels_count\n",
    "hidden_layers = [(), (neurons_1), (neurons_2)]\n",
    "random_state = 19\n",
    "activations = ['relu', 'logistic']\n",
    "alphas = [0.0001, 0.0005, 0.001, 0.02, 0.2]\n",
    "\n",
    "for hidden_layer in hidden_layers:\n",
    "    for activation in activations:\n",
    "        for alpha in alphas: \n",
    "            print '------------------------------'\n",
    "            start_time = time.time()\n",
    "            print 'hidden_layer: ' + str(hidden_layer)\n",
    "            print 'activation: ' + str(activation)\n",
    "            print 'alphas: ' + str(alpha)            \n",
    "            classifier = MLPClassifier(hidden_layer_sizes=hidden_layer, random_state=random_state, \n",
    "                                       alpha=alpha, activation=activation)\n",
    "            classifier.fit(X_train, y_train)                         \n",
    "            predictions = classifier.predict(X_cross_validation)\n",
    "            confusion_matrix = metrics.confusion_matrix(y_cross_validation, predictions, labels=index_to_label_map.keys())\n",
    "            print_summary_statistics(confusion_matrix, 0)\n",
    "            print_f_scores(y_cross_validation, predictions, index_to_label_map.keys())\n",
    "            \n",
    "            total_time = time.time() - start_time\n",
    "            print 'total prediction time: ' + str(total_time) + ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "content = []\n",
    "with open('/Users/haris/Desktop/NN') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "list = []\n",
    "item = {}\n",
    "for line in content:\n",
    "    if line.startswith('-------------------------'):\n",
    "        list.append(item)\n",
    "        item = {}\n",
    "    else:\n",
    "        splits = line.split(\": \")\n",
    "        splits[0] = splits[0].replace(' ', '_')\n",
    "        splits[1] = splits[1].replace('\\n', '')\n",
    "\n",
    "        if splits[0] == 'weighted':\n",
    "            item[splits[0]] = float(splits[1])\n",
    "        else:\n",
    "            item[splits[0]] = splits[1]\n",
    "        # print splits[0].replace(' ', '_') + '=' + item[splits[0].replace(' ', '_')]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare accuracy of various neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "weighted: 0.972082315961\n",
      "hidden_layer: 5\n",
      "activation: logistic\n",
      "alphas: 0.2\n",
      "--------\n",
      "weighted: 0.983623682519\n",
      "hidden_layer: 104\n",
      "activation: logistic\n",
      "alphas: 0.2\n",
      "--------\n",
      "weighted: 0.988387873005\n",
      "hidden_layer: ()\n",
      "activation: relu\n",
      "alphas: 0.2\n",
      "--------\n",
      "weighted: 0.988387873005\n",
      "hidden_layer: ()\n",
      "activation: logistic\n",
      "alphas: 0.2\n",
      "--------\n",
      "weighted: 0.990609117787\n",
      "hidden_layer: 5\n",
      "activation: relu\n",
      "alphas: 0.2\n",
      "--------\n",
      "weighted: 0.991900377612\n",
      "hidden_layer: 104\n",
      "activation: relu\n",
      "alphas: 0.2\n",
      "--------\n",
      "weighted: 0.992993444672\n",
      "hidden_layer: 5\n",
      "activation: logistic\n",
      "alphas: 0.02\n",
      "--------\n",
      "weighted: 0.993775658956\n",
      "hidden_layer: ()\n",
      "activation: relu\n",
      "alphas: 0.02\n",
      "--------\n",
      "weighted: 0.993775658956\n",
      "hidden_layer: ()\n",
      "activation: logistic\n",
      "alphas: 0.02\n",
      "--------\n",
      "weighted: 0.993876658763\n",
      "hidden_layer: 104\n",
      "activation: logistic\n",
      "alphas: 0.02\n",
      "--------\n",
      "weighted: 0.994377821091\n",
      "hidden_layer: 5\n",
      "activation: relu\n",
      "alphas: 0.02\n",
      "--------\n",
      "weighted: 0.996346931121\n",
      "hidden_layer: ()\n",
      "activation: relu\n",
      "alphas: 0.001\n",
      "--------\n",
      "weighted: 0.996356407785\n",
      "hidden_layer: ()\n",
      "activation: logistic\n",
      "alphas: 0.001\n",
      "--------\n",
      "weighted: 0.996513788287\n",
      "hidden_layer: ()\n",
      "activation: logistic\n",
      "alphas: 0.0005\n",
      "--------\n",
      "weighted: 0.996516249504\n",
      "hidden_layer: 5\n",
      "activation: logistic\n",
      "alphas: 0.001\n",
      "--------\n",
      "weighted: 0.996530909473\n",
      "hidden_layer: ()\n",
      "activation: relu\n",
      "alphas: 0.0005\n",
      "--------\n",
      "weighted: 0.99693158402\n",
      "hidden_layer: 5\n",
      "activation: logistic\n",
      "alphas: 0.0005\n",
      "--------\n",
      "weighted: 0.997151001686\n",
      "hidden_layer: ()\n",
      "activation: logistic\n",
      "alphas: 0.0001\n",
      "--------\n",
      "weighted: 0.997151003655\n",
      "hidden_layer: ()\n",
      "activation: relu\n",
      "alphas: 0.0001\n",
      "--------\n",
      "weighted: 0.997176987457\n",
      "hidden_layer: 104\n",
      "activation: relu\n",
      "alphas: 0.02\n",
      "--------\n",
      "weighted: 0.997494230553\n",
      "hidden_layer: 5\n",
      "activation: logistic\n",
      "alphas: 0.0001\n",
      "--------\n",
      "weighted: 0.997873377224\n",
      "hidden_layer: 104\n",
      "activation: logistic\n",
      "alphas: 0.001\n",
      "--------\n",
      "weighted: 0.998000838267\n",
      "hidden_layer: 104\n",
      "activation: logistic\n",
      "alphas: 0.0005\n",
      "--------\n",
      "weighted: 0.998187234212\n",
      "hidden_layer: 5\n",
      "activation: relu\n",
      "alphas: 0.001\n",
      "--------\n",
      "weighted: 0.998247728618\n",
      "hidden_layer: 5\n",
      "activation: relu\n",
      "alphas: 0.0005\n",
      "--------\n",
      "weighted: 0.998711918642\n",
      "hidden_layer: 5\n",
      "activation: relu\n",
      "alphas: 0.0001\n",
      "--------\n",
      "weighted: 0.998947897166\n",
      "hidden_layer: 104\n",
      "activation: logistic\n",
      "alphas: 0.0001\n",
      "--------\n",
      "weighted: 0.999111550608\n",
      "hidden_layer: 104\n",
      "activation: relu\n",
      "alphas: 0.001\n",
      "--------\n",
      "weighted: 0.99919375977\n",
      "hidden_layer: 104\n",
      "activation: relu\n",
      "alphas: 0.0005\n",
      "--------\n",
      "weighted: 0.999264138536\n",
      "hidden_layer: 104\n",
      "activation: relu\n",
      "alphas: 0.0001\n"
     ]
    }
   ],
   "source": [
    "list.sort(key=lambda x: x['weighted'])\n",
    "\n",
    "for item in list:\n",
    "    print '--------'\n",
    "    print 'weighted: ' + str(item['weighted'])\n",
    "    print 'hidden_layer: ' + item['hidden_layer']\n",
    "    print 'activation: ' + item['activation']\n",
    "    print 'alphas: ' + item['alphas']   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: smaller lambda values are more effective<br>\n",
    "Best performing parameters: <br>hidden_layer: 104<br>activation: relu<br>alphas: 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv loaded\n",
      "214999 test rows\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"/Users/haris/Desktop/kdd_datasets/test.csv\")\n",
    "print \"csv loaded\"\n",
    "print str(len(test)) + ' test rows'\n",
    "test['label'] = test['label'].map(lambda item: label_to_index_map[item])\n",
    "\n",
    "y_test = test['label']\n",
    "X_test = test.drop('label', 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a neural network using best paramters and run on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 214999\n",
      "normal: 162563\n",
      "anomalous: 52436\n",
      "total correctly identified: 214836(99.9241856939%)\n",
      "normal correctly identified: 162532(99.98093047%)\n",
      "anomalous correctly identified: 52304(99.7482645511%)\n",
      "micro: 0.999241856939\n",
      "macro: 0.561487757204\n",
      "weighted: 0.999196020092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haris/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/haris/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "final_classifier = MLPClassifier(hidden_layer_sizes=neurons_2, random_state=random_state, \n",
    "                                       alpha=0.0001, activation='relu')\n",
    "final_classifier.fit(X_train, y_train)                         \n",
    "test_predictions = final_classifier.predict(X_test)\n",
    "test_confusion_matrix = metrics.confusion_matrix(y_test, test_predictions, labels=index_to_label_map.keys())\n",
    "print_summary_statistics(test_confusion_matrix, 0)\n",
    "print_f_scores(y_test, test_predictions, index_to_label_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
